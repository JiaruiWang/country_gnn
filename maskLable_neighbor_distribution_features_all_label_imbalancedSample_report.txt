Epoch: 001, Loss: 0.9666230083
Epoch: 002, Loss: 0.6695280671
Epoch: 003, Loss: 0.6227581501
Epoch: 004, Loss: 0.5987567306
Epoch: 005, Loss: 0.5873674154
Epoch: 006, Loss: 0.5778862238
Epoch: 007, Loss: 0.5710182190
Epoch: 008, Loss: 0.5655179620
Epoch: 009, Loss: 0.5607504249
Epoch: 010, Loss: 0.5574768186
              precision    recall  f1-score   support

           0       0.78      0.90      0.84      5980
           1       0.87      0.92      0.89      1926
           2       0.83      0.90      0.87     10875
           3       0.81      0.90      0.86      3706
           4       0.87      0.76      0.81     87224
           5       0.84      0.87      0.86     12723
           6       0.77      0.91      0.84      5130
           7       0.35      0.90      0.51       524
           8       0.88      0.87      0.87     41061
           9       0.83      0.87      0.85     13991
          10       0.75      0.89      0.82      2688
          11       0.78      0.89      0.83      3289
          12       0.81      0.76      0.78     25976
          13       0.83      0.88      0.85      9712
          14       0.83      0.87      0.85      5953
          15       0.82      0.89      0.85      6669
          16       0.71      0.88      0.79      3753
          17       0.83      0.87      0.85      6373
          18       0.82      0.94      0.88      3883
          19       0.78      0.85      0.81      8540
          20       0.87      0.88      0.87     14401
          21       0.90      0.89      0.89     17392
          22       0.82      0.89      0.86      9365
          23       0.72      0.88      0.79      2732
          24       0.75      0.86      0.80      6494
          25       0.84      0.91      0.87      2805
          26       0.82      0.93      0.87      2713
          27       0.72      0.87      0.79      4375
          28       0.76      0.90      0.83      3114
          29       0.74      0.88      0.80     12048
          30       0.70      0.83      0.76      3053
          31       0.86      0.64      0.74     53878
          32       0.86      0.87      0.86     18099
          33       0.77      0.91      0.83      1262
          34       0.83      0.87      0.85     16802
          35       0.79      0.85      0.82      5715
          36       0.84      0.91      0.88      9473
          37       0.82      0.80      0.81     23381
          38       0.76      0.91      0.83      2071
          39       0.83      0.90      0.86      7503
          40       0.81      0.92      0.86      1733
          41       0.82      0.89      0.85      8679
          42       0.79      0.78      0.78     52030
          43       0.73      0.87      0.79      4530
          44       0.76      0.92      0.84      1900
          45       0.84      0.87      0.85     13368
          46       0.88      0.87      0.87     16204
          47       0.12      0.76      0.21       433
          48       0.64      0.86      0.73      1794
          49       0.87      0.91      0.89     11387
          50       0.61      0.84      0.71      1290

    accuracy                           0.82    590000
   macro avg       0.78      0.87      0.81    590000
weighted avg       0.83      0.82      0.82    590000

486107 590000
              precision    recall  f1-score   support

           0       0.92      0.90      0.91      1000
           1       0.98      0.91      0.94      1000
           2       0.91      0.90      0.90      1000
           3       0.96      0.89      0.92      1000
           4       0.49      0.78      0.60      1000
           5       0.85      0.88      0.86      1000
           6       0.93      0.92      0.93      1000
           7       0.96      0.88      0.92      1000
           8       0.75      0.85      0.80      1000
           9       0.87      0.89      0.88      1000
          10       0.96      0.91      0.93      1000
          11       0.93      0.87      0.90      1000
          12       0.73      0.75      0.74      1000
          13       0.90      0.90      0.90      1000
          14       0.93      0.88      0.90      1000
          15       0.90      0.90      0.90      1000
          16       0.93      0.89      0.91      1000
          17       0.94      0.89      0.91      1000
          18       0.95      0.93      0.94      1000
          19       0.85      0.86      0.85      1000
          20       0.85      0.87      0.86      1000
          21       0.90      0.89      0.89      1000
          22       0.88      0.89      0.89      1000
          23       0.94      0.87      0.90      1000
          24       0.89      0.85      0.87      1000
          25       0.95      0.92      0.93      1000
          26       0.96      0.93      0.94      1000
          27       0.92      0.87      0.89      1000
          28       0.92      0.90      0.91      1000
          29       0.87      0.89      0.88      1000
          30       0.93      0.84      0.89      1000
          31       0.63      0.67      0.65      1000
          32       0.85      0.88      0.87      1000
          33       0.97      0.92      0.95      1000
          34       0.86      0.87      0.86      1000
          35       0.92      0.88      0.90      1000
          36       0.92      0.93      0.92      1000
          37       0.78      0.82      0.80      1000
          38       0.96      0.90      0.93      1000
          39       0.93      0.90      0.91      1000
          40       0.96      0.91      0.93      1000
          41       0.90      0.89      0.90      1000
          42       0.50      0.75      0.60      1000
          43       0.89      0.87      0.88      1000
          44       0.96      0.90      0.93      1000
          45       0.85      0.88      0.87      1000
          46       0.85      0.86      0.86      1000
          47       0.89      0.74      0.81      1000
          48       0.94      0.88      0.91      1000
          49       0.91      0.92      0.91      1000
          50       0.94      0.87      0.90      1000

    accuracy                           0.87     51000
   macro avg       0.88      0.87      0.88     51000
weighted avg       0.88      0.87      0.88     51000

44515 51000
Train: 0.0000, Val: 0.8239, Test: 0.8728

Epoch: 011, Loss: 0.5514575243
Epoch: 012, Loss: 0.5492359400
Epoch: 013, Loss: 0.5461276174
Epoch: 014, Loss: 0.5438394547
Epoch: 015, Loss: 0.5403830409
Epoch: 016, Loss: 0.5380933285
Epoch: 017, Loss: 0.5358844995
Epoch: 018, Loss: 0.5332556963
Epoch: 019, Loss: 0.5316776037
Epoch: 020, Loss: 0.5301124454
              precision    recall  f1-score   support

           0       0.79      0.90      0.84      5980
           1       0.85      0.92      0.88      1926
           2       0.84      0.90      0.87     10875
           3       0.80      0.91      0.85      3706
           4       0.91      0.71      0.80     87224
           5       0.80      0.88      0.84     12723
           6       0.77      0.92      0.84      5130
           7       0.37      0.91      0.53       524
           8       0.88      0.87      0.87     41061
           9       0.81      0.88      0.84     13991
          10       0.61      0.91      0.73      2688
          11       0.76      0.90      0.82      3289
          12       0.75      0.79      0.77     25976
          13       0.81      0.89      0.85      9712
          14       0.82      0.87      0.85      5953
          15       0.82      0.90      0.85      6669
          16       0.69      0.90      0.78      3753
          17       0.84      0.88      0.86      6373
          18       0.84      0.94      0.89      3883
          19       0.79      0.85      0.82      8540
          20       0.86      0.89      0.88     14401
          21       0.88      0.90      0.89     17392
          22       0.80      0.90      0.84      9365
          23       0.73      0.89      0.80      2732
          24       0.72      0.87      0.79      6494
          25       0.82      0.92      0.87      2805
          26       0.81      0.93      0.87      2713
          27       0.63      0.90      0.74      4375
          28       0.76      0.91      0.83      3114
          29       0.77      0.88      0.82     12048
          30       0.68      0.85      0.75      3053
          31       0.83      0.67      0.74     53878
          32       0.85      0.87      0.86     18099
          33       0.67      0.92      0.78      1262
          34       0.85      0.87      0.86     16802
          35       0.71      0.87      0.78      5715
          36       0.84      0.92      0.88      9473
          37       0.80      0.81      0.80     23381
          38       0.75      0.92      0.83      2071
          39       0.81      0.91      0.86      7503
          40       0.79      0.92      0.85      1733
          41       0.81      0.90      0.85      8679
          42       0.87      0.74      0.80     52030
          43       0.64      0.88      0.74      4530
          44       0.72      0.93      0.81      1900
          45       0.85      0.87      0.86     13368
          46       0.85      0.88      0.86     16204
          47       0.13      0.84      0.23       433
          48       0.63      0.88      0.73      1794
          49       0.86      0.92      0.89     11387
          50       0.61      0.85      0.71      1290

    accuracy                           0.82    590000
   macro avg       0.76      0.88      0.81    590000
weighted avg       0.83      0.82      0.82    590000

484400 590000
              precision    recall  f1-score   support

           0       0.93      0.91      0.92      1000
           1       0.98      0.92      0.95      1000
           2       0.91      0.90      0.90      1000
           3       0.95      0.90      0.92      1000
           4       0.63      0.71      0.66      1000
           5       0.83      0.90      0.86      1000
           6       0.93      0.93      0.93      1000
           7       0.96      0.90      0.93      1000
           8       0.77      0.86      0.81      1000
           9       0.86      0.89      0.88      1000
          10       0.93      0.92      0.93      1000
          11       0.92      0.89      0.91      1000
          12       0.68      0.78      0.72      1000
          13       0.90      0.90      0.90      1000
          14       0.93      0.88      0.90      1000
          15       0.91      0.90      0.91      1000
          16       0.92      0.90      0.91      1000
          17       0.93      0.90      0.91      1000
          18       0.96      0.93      0.94      1000
          19       0.87      0.85      0.86      1000
          20       0.84      0.88      0.86      1000
          21       0.88      0.90      0.89      1000
          22       0.88      0.91      0.89      1000
          23       0.94      0.88      0.91      1000
          24       0.88      0.86      0.87      1000
          25       0.95      0.92      0.94      1000
          26       0.96      0.93      0.95      1000
          27       0.90      0.90      0.90      1000
          28       0.93      0.91      0.92      1000
          29       0.89      0.89      0.89      1000
          30       0.94      0.86      0.90      1000
          31       0.60      0.69      0.64      1000
          32       0.85      0.89      0.87      1000
          33       0.95      0.93      0.94      1000
          34       0.88      0.86      0.87      1000
          35       0.89      0.89      0.89      1000
          36       0.92      0.93      0.93      1000
          37       0.77      0.83      0.80      1000
          38       0.96      0.92      0.94      1000
          39       0.93      0.90      0.92      1000
          40       0.96      0.92      0.94      1000
          41       0.90      0.90      0.90      1000
          42       0.64      0.71      0.67      1000
          43       0.87      0.89      0.88      1000
          44       0.95      0.92      0.93      1000
          45       0.87      0.88      0.87      1000
          46       0.84      0.88      0.86      1000
          47       0.91      0.81      0.86      1000
          48       0.95      0.89      0.92      1000
          49       0.91      0.93      0.92      1000
          50       0.93      0.88      0.91      1000

    accuracy                           0.88     51000
   macro avg       0.89      0.88      0.88     51000
weighted avg       0.89      0.88      0.88     51000

44911 51000
Train: 0.0000, Val: 0.8210, Test: 0.8806

Epoch: 021, Loss: 0.5290842652
Epoch: 022, Loss: 0.5279307961
Epoch: 023, Loss: 0.5260016918
Epoch: 024, Loss: 0.5251572132
Epoch: 025, Loss: 0.5244610310
Epoch: 026, Loss: 0.5227699876
Epoch: 027, Loss: 0.5215772986
Epoch: 028, Loss: 0.5229443908
Epoch: 029, Loss: 0.5204628706
Epoch: 030, Loss: 0.5201484561

              precision    recall  f1-score   support

           0       0.78      0.91      0.84      5980
           1       0.83      0.92      0.88      1926
           2       0.83      0.91      0.87     10875
           3       0.76      0.92      0.83      3706
           4       0.89      0.75      0.81     87224
           5       0.84      0.87      0.86     12723
           6       0.80      0.91      0.85      5130
           7       0.39      0.91      0.55       524
           8       0.89      0.87      0.88     41061
           9       0.83      0.88      0.85     13991
          10       0.71      0.90      0.80      2688
          11       0.75      0.90      0.82      3289
          12       0.79      0.78      0.78     25976
          13       0.82      0.89      0.85      9712
          14       0.82      0.88      0.85      5953
          15       0.82      0.90      0.85      6669
          16       0.72      0.89      0.80      3753
          17       0.80      0.89      0.85      6373
          18       0.83      0.94      0.88      3883
          19       0.79      0.85      0.82      8540
          20       0.88      0.88      0.88     14401
          21       0.89      0.90      0.90     17392
          22       0.81      0.90      0.85      9365
          23       0.72      0.89      0.80      2732
          24       0.72      0.87      0.79      6494
          25       0.84      0.92      0.88      2805
          26       0.80      0.94      0.87      2713
          27       0.70      0.88      0.78      4375
          28       0.75      0.91      0.83      3114
          29       0.79      0.87      0.83     12048
          30       0.60      0.86      0.70      3053
          31       0.81      0.69      0.75     53878
          32       0.87      0.87      0.87     18099
          33       0.75      0.92      0.82      1262
          34       0.84      0.88      0.86     16802
          35       0.79      0.86      0.82      5715
          36       0.86      0.91      0.89      9473
          37       0.82      0.81      0.82     23381
          38       0.74      0.92      0.82      2071
          39       0.81      0.91      0.86      7503
          40       0.80      0.92      0.85      1733
          41       0.81      0.90      0.85      8679
          42       0.87      0.74      0.80     52030
          43       0.73      0.88      0.80      4530
          44       0.74      0.93      0.83      1900
          45       0.84      0.87      0.86     13368
          46       0.86      0.88      0.87     16204
          47       0.14      0.83      0.24       433
          48       0.65      0.87      0.75      1794
          49       0.86      0.92      0.89     11387
          50       0.60      0.86      0.70      1290

    accuracy                           0.83    590000
   macro avg       0.77      0.88      0.81    590000
weighted avg       0.83      0.83      0.83    590000

488149 590000

              precision    recall  f1-score   support

           0       0.92      0.91      0.92      1000
           1       0.98      0.92      0.95      1000
           2       0.91      0.90      0.90      1000
           3       0.94      0.91      0.93      1000
           4       0.54      0.74      0.63      1000
           5       0.86      0.89      0.88      1000
           6       0.94      0.91      0.92      1000
           7       0.97      0.91      0.94      1000
           8       0.77      0.85      0.81      1000
           9       0.87      0.89      0.88      1000
          10       0.95      0.91      0.93      1000
          11       0.93      0.89      0.91      1000
          12       0.72      0.77      0.74      1000
          13       0.90      0.91      0.90      1000
          14       0.92      0.88      0.90      1000
          15       0.91      0.91      0.91      1000
          16       0.93      0.88      0.91      1000
          17       0.92      0.91      0.91      1000
          18       0.95      0.93      0.94      1000
          19       0.87      0.86      0.86      1000
          20       0.86      0.87      0.87      1000
          21       0.90      0.90      0.90      1000
          22       0.88      0.90      0.89      1000
          23       0.94      0.88      0.91      1000
          24       0.88      0.87      0.87      1000
          25       0.96      0.92      0.94      1000
          26       0.96      0.94      0.95      1000
          27       0.91      0.88      0.89      1000
          28       0.93      0.91      0.92      1000
          29       0.91      0.88      0.89      1000
          30       0.91      0.87      0.89      1000
          31       0.55      0.72      0.62      1000
          32       0.88      0.88      0.88      1000
          33       0.96      0.93      0.95      1000
          34       0.86      0.87      0.86      1000
          35       0.92      0.88      0.90      1000
          36       0.93      0.92      0.92      1000
          37       0.78      0.82      0.80      1000
          38       0.94      0.91      0.93      1000
          39       0.93      0.90      0.92      1000
          40       0.96      0.92      0.94      1000
          41       0.90      0.90      0.90      1000
          42       0.62      0.71      0.66      1000
          43       0.89      0.88      0.88      1000
          44       0.96      0.92      0.94      1000
          45       0.86      0.88      0.87      1000
          46       0.85      0.87      0.86      1000
          47       0.91      0.80      0.85      1000
          48       0.96      0.89      0.92      1000
          49       0.91      0.92      0.92      1000
          50       0.93      0.88      0.91      1000

    accuracy                           0.88     51000
   macro avg       0.89      0.88      0.88     51000
weighted avg       0.89      0.88      0.88     51000

44881 51000
Train: 0.0000, Val: 0.8274, Test: 0.8800

Epoch: 031, Loss: 0.5204731226
Epoch: 032, Loss: 0.5200250745
Epoch: 033, Loss: 0.5190290809
Epoch: 034, Loss: 0.5188909769
Epoch: 035, Loss: 0.5183885098
Epoch: 036, Loss: 0.5176459551
Epoch: 037, Loss: 0.5184659362
Epoch: 038, Loss: 0.5177022219
Epoch: 039, Loss: 0.5178824067
Epoch: 040, Loss: 0.5170148611
              precision    recall  f1-score   support

           0       0.78      0.91      0.84      5980
           1       0.82      0.93      0.87      1926
           2       0.83      0.91      0.87     10875
           3       0.74      0.92      0.82      3706
           4       0.89      0.74      0.81     87224
           5       0.84      0.86      0.85     12723
           6       0.77      0.92      0.84      5130
           7       0.32      0.92      0.48       524
           8       0.90      0.86      0.88     41061
           9       0.82      0.88      0.85     13991
          10       0.73      0.90      0.81      2688
          11       0.76      0.90      0.82      3289
          12       0.82      0.77      0.79     25976
          13       0.81      0.90      0.85      9712
          14       0.82      0.87      0.85      5953
          15       0.82      0.89      0.86      6669
          16       0.69      0.90      0.78      3753
          17       0.81      0.89      0.85      6373
          18       0.83      0.94      0.88      3883
          19       0.77      0.85      0.81      8540
          20       0.88      0.88      0.88     14401
          21       0.87      0.91      0.89     17392
          22       0.81      0.89      0.85      9365
          23       0.67      0.89      0.76      2732
          24       0.72      0.88      0.79      6494
          25       0.82      0.92      0.86      2805
          26       0.80      0.93      0.86      2713
          27       0.61      0.90      0.72      4375
          28       0.74      0.91      0.82      3114
          29       0.77      0.88      0.82     12048
          30       0.58      0.86      0.69      3053
          31       0.81      0.69      0.75     53878
          32       0.85      0.88      0.86     18099
          33       0.74      0.93      0.82      1262
          34       0.85      0.86      0.86     16802
          35       0.73      0.87      0.80      5715
          36       0.84      0.92      0.88      9473
          37       0.81      0.81      0.81     23381
          38       0.73      0.92      0.82      2071
          39       0.84      0.90      0.87      7503
          40       0.79      0.92      0.85      1733
          41       0.82      0.90      0.85      8679
          42       0.88      0.73      0.80     52030
          43       0.72      0.89      0.79      4530
          44       0.74      0.93      0.83      1900
          45       0.86      0.87      0.86     13368
          46       0.87      0.87      0.87     16204
          47       0.13      0.84      0.23       433
          48       0.62      0.89      0.73      1794
          49       0.88      0.91      0.89     11387
          50       0.52      0.87      0.65      1290

    accuracy                           0.83    590000
   macro avg       0.76      0.88      0.81    590000
weighted avg       0.84      0.83      0.83    590000

486912 590000

              precision    recall  f1-score   support

           0       0.92      0.91      0.92      1000
           1       0.97      0.92      0.94      1000
           2       0.90      0.91      0.90      1000
           3       0.93      0.91      0.92      1000
           4       0.55      0.73      0.63      1000
           5       0.87      0.88      0.87      1000
           6       0.93      0.92      0.93      1000
           7       0.95      0.92      0.93      1000
           8       0.79      0.85      0.82      1000
           9       0.86      0.89      0.88      1000
          10       0.96      0.91      0.93      1000
          11       0.93      0.89      0.91      1000
          12       0.77      0.77      0.77      1000
          13       0.89      0.91      0.90      1000
          14       0.93      0.88      0.90      1000
          15       0.91      0.90      0.91      1000
          16       0.92      0.89      0.91      1000
          17       0.93      0.91      0.92      1000
          18       0.96      0.93      0.94      1000
          19       0.86      0.86      0.86      1000
          20       0.87      0.87      0.87      1000
          21       0.87      0.90      0.89      1000
          22       0.88      0.90      0.89      1000
          23       0.92      0.88      0.90      1000
          24       0.88      0.88      0.88      1000
          25       0.96      0.93      0.94      1000
          26       0.96      0.94      0.95      1000
          27       0.88      0.89      0.89      1000
          28       0.92      0.92      0.92      1000
          29       0.89      0.88      0.88      1000
          30       0.92      0.87      0.89      1000
          31       0.56      0.71      0.62      1000
          32       0.86      0.89      0.88      1000
          33       0.97      0.93      0.95      1000
          34       0.88      0.86      0.87      1000
          35       0.90      0.88      0.89      1000
          36       0.92      0.93      0.93      1000
          37       0.78      0.82      0.80      1000
          38       0.95      0.92      0.93      1000
          39       0.94      0.89      0.91      1000
          40       0.96      0.93      0.94      1000
          41       0.90      0.90      0.90      1000
          42       0.66      0.69      0.68      1000
          43       0.88      0.89      0.88      1000
          44       0.96      0.91      0.93      1000
          45       0.87      0.87      0.87      1000
          46       0.87      0.87      0.87      1000
          47       0.91      0.82      0.86      1000
          48       0.95      0.90      0.92      1000
          49       0.92      0.92      0.92      1000
          50       0.92      0.90      0.91      1000

    accuracy                           0.88     51000
   macro avg       0.89      0.88      0.88     51000
weighted avg       0.89      0.88      0.88     51000

44954 51000
Train: 0.0000, Val: 0.8253, Test: 0.8815

Epoch: 041, Loss: 0.5165728331
Epoch: 042, Loss: 0.5161299109
Epoch: 043, Loss: 0.5158037543
Epoch: 044, Loss: 0.5167726874
Epoch: 045, Loss: 0.5163733363
Epoch: 046, Loss: 0.5170480013
Epoch: 047, Loss: 0.5163213611
Epoch: 048, Loss: 0.5149104595
Epoch: 049, Loss: 0.5148208141
Epoch: 050, Loss: 0.5154638290
              precision    recall  f1-score   support

           0       0.80      0.90      0.85      5980
           1       0.83      0.92      0.87      1926
           2       0.84      0.91      0.87     10875
           3       0.76      0.92      0.83      3706
           4       0.86      0.77      0.81     87224
           5       0.85      0.86      0.86     12723
           6       0.78      0.92      0.84      5130
           7       0.36      0.91      0.52       524
           8       0.90      0.86      0.88     41061
           9       0.84      0.87      0.86     13991
          10       0.71      0.90      0.80      2688
          11       0.77      0.90      0.83      3289
          12       0.83      0.76      0.80     25976
          13       0.82      0.89      0.85      9712
          14       0.81      0.88      0.84      5953
          15       0.83      0.89      0.86      6669
          16       0.69      0.90      0.78      3753
          17       0.79      0.89      0.84      6373
          18       0.83      0.94      0.88      3883
          19       0.77      0.86      0.81      8540
          20       0.87      0.89      0.88     14401
          21       0.88      0.90      0.89     17392
          22       0.81      0.90      0.85      9365
          23       0.71      0.89      0.79      2732
          24       0.75      0.87      0.81      6494
          25       0.81      0.92      0.86      2805
          26       0.80      0.94      0.86      2713
          27       0.68      0.88      0.77      4375
          28       0.77      0.91      0.83      3114
          29       0.77      0.87      0.82     12048
          30       0.54      0.87      0.67      3053
          31       0.84      0.68      0.75     53878
          32       0.86      0.88      0.87     18099
          33       0.68      0.93      0.78      1262
          34       0.85      0.87      0.86     16802
          35       0.73      0.87      0.79      5715
          36       0.86      0.91      0.88      9473
          37       0.82      0.81      0.82     23381
          38       0.75      0.92      0.82      2071
          39       0.85      0.90      0.87      7503
          40       0.78      0.92      0.84      1733
          41       0.83      0.89      0.86      8679
          42       0.87      0.74      0.80     52030
          43       0.71      0.89      0.79      4530
          44       0.76      0.93      0.84      1900
          45       0.87      0.85      0.86     13368
          46       0.88      0.87      0.88     16204
          47       0.13      0.84      0.22       433
          48       0.62      0.89      0.73      1794
          49       0.87      0.91      0.89     11387
          50       0.54      0.87      0.67      1290

    accuracy                           0.83    590000
   macro avg       0.77      0.88      0.81    590000
weighted avg       0.84      0.83      0.83    590000

488186 590000
              precision    recall  f1-score   support

           0       0.93      0.90      0.92      1000
           1       0.98      0.92      0.94      1000
           2       0.91      0.90      0.90      1000
           3       0.94      0.91      0.92      1000
           4       0.50      0.77      0.60      1000
           5       0.87      0.88      0.87      1000
           6       0.93      0.92      0.92      1000
           7       0.96      0.91      0.94      1000
           8       0.79      0.84      0.81      1000
           9       0.88      0.88      0.88      1000
          10       0.95      0.92      0.93      1000
          11       0.93      0.89      0.91      1000
          12       0.77      0.76      0.76      1000
          13       0.91      0.91      0.91      1000
          14       0.92      0.89      0.90      1000
          15       0.92      0.90      0.91      1000
          16       0.93      0.90      0.91      1000
          17       0.92      0.91      0.91      1000
          18       0.95      0.93      0.94      1000
          19       0.85      0.86      0.86      1000
          20       0.84      0.88      0.86      1000
          21       0.89      0.91      0.90      1000
          22       0.87      0.90      0.89      1000
          23       0.94      0.88      0.91      1000
          24       0.89      0.86      0.88      1000
          25       0.95      0.93      0.94      1000
          26       0.96      0.94      0.95      1000
          27       0.91      0.89      0.90      1000
          28       0.93      0.91      0.92      1000
          29       0.89      0.88      0.89      1000
          30       0.89      0.88      0.88      1000
          31       0.60      0.69      0.64      1000
          32       0.86      0.89      0.88      1000
          33       0.95      0.93      0.94      1000
          34       0.87      0.86      0.86      1000
          35       0.90      0.89      0.89      1000
          36       0.92      0.92      0.92      1000
          37       0.78      0.82      0.80      1000
          38       0.95      0.91      0.93      1000
          39       0.94      0.89      0.92      1000
          40       0.96      0.93      0.94      1000
          41       0.91      0.90      0.90      1000
          42       0.64      0.71      0.67      1000
          43       0.88      0.89      0.89      1000
          44       0.97      0.91      0.94      1000
          45       0.89      0.86      0.88      1000
          46       0.87      0.86      0.86      1000
          47       0.90      0.81      0.85      1000
          48       0.95      0.90      0.92      1000
          49       0.92      0.92      0.92      1000
          50       0.92      0.90      0.91      1000

    accuracy                           0.88     51000
   macro avg       0.89      0.88      0.88     51000
weighted avg       0.89      0.88      0.88     51000

44925 51000
Train: 0.0000, Val: 0.8274, Test: 0.8809

