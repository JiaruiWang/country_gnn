Epoch: 001, Loss: 0.0000728711 Train: 0.8478, Val: 0.7961, Test: 0.8490
Epoch: 002, Loss: 0.0000272156 Train: 0.8552, Val: 0.7995, Test: 0.8554
Epoch: 003, Loss: 0.0000260864 Train: 0.8541, Val: 0.8032, Test: 0.8547
Epoch: 004, Loss: 0.0000264845 Train: 0.8553, Val: 0.8044, Test: 0.8559
Epoch: 005, Loss: 0.0000257051 Train: 0.8551, Val: 0.8028, Test: 0.8557
Epoch: 006, Loss: 0.0000257406 Train: 0.8576, Val: 0.8055, Test: 0.8589
Epoch: 007, Loss: 0.0000256603 Train: 0.8559, Val: 0.8040, Test: 0.8559
Epoch: 008, Loss: 0.0000264942 Train: 0.8419, Val: 0.7895, Test: 0.8418
Epoch: 009, Loss: 0.0000265839 Train: 0.8562, Val: 0.8073, Test: 0.8557
Epoch: 010, Loss: 0.0000261031 Train: 0.8552, Val: 0.7998, Test: 0.8557
Epoch: 011, Loss: 0.0000256490 Train: 0.8585, Val: 0.8046, Test: 0.8597
Epoch: 012, Loss: 0.0000265773 Train: 0.8532, Val: 0.8021, Test: 0.8539


Training report:
              precision    recall  f1-score   support

           0       0.94      0.86      0.90    102794
           1       0.98      0.91      0.94    102138
           2       0.89      0.88      0.89    102512
           3       0.94      0.89      0.92    103096
           4       0.54      0.67      0.60    102249
           5       0.77      0.89      0.82    102540
           6       0.94      0.89      0.92    102500
           7       0.97      0.88      0.92    101974
           8       0.66      0.87      0.75    102442
           9       0.81      0.86      0.83    102980
          10       0.97      0.88      0.92    102598
          11       0.94      0.86      0.90    101910
          12       0.64      0.75      0.69    102593
          13       0.90      0.87      0.89    102490
          14       0.92      0.85      0.88    103045
          15       0.88      0.88      0.88    102039
          16       0.88      0.88      0.88    102680
          17       0.94      0.87      0.90    102813
          18       0.94      0.92      0.93    102695
          19       0.73      0.85      0.78    102748
          20       0.86      0.86      0.86    102855
          21       0.86      0.89      0.87    101915
          22       0.84      0.88      0.86    102574
          23       0.95      0.86      0.90    102522
          24       0.89      0.82      0.85    102483
          25       0.96      0.90      0.93    102612
          26       0.95      0.91      0.93    102619
          27       0.93      0.84      0.88    102802
          28       0.91      0.91      0.91    102809
          29       0.90      0.81      0.85    102866
          30       0.93      0.82      0.87    102585
          31       0.46      0.63      0.54    102734
          32       0.86      0.84      0.85    102426
          33       0.97      0.91      0.94    102173
          34       0.79      0.87      0.83    102012
          35       0.90      0.84      0.87    102736
          36       0.89      0.91      0.90    102749
          37       0.74      0.76      0.75    102827
          38       0.96      0.90      0.93    103092
          39       0.91      0.89      0.90    102681
          40       0.96      0.90      0.92    102583
          41       0.88      0.88      0.88    102235
          42       0.52      0.72      0.61    102438
          43       0.91      0.84      0.87    102520
          44       0.95      0.91      0.93    102821
          45       0.85      0.82      0.84    103416
          46       0.83      0.86      0.85    102328
          47       0.83      0.77      0.80    102423
          48       0.94      0.84      0.88    103332
          49       0.90      0.89      0.90    102460
          50       0.97      0.78      0.86    102931

    accuracy                           0.85   5232395
   macro avg       0.87      0.85      0.86   5232395
weighted avg       0.87      0.85      0.86   5232395

4462575 5232395

Validation report:
              precision    recall  f1-score   support

           0       0.83      0.85      0.84      5986
           1       0.86      0.92      0.89      1857
           2       0.83      0.88      0.86     10885
           3       0.78      0.89      0.83      3824
           4       0.89      0.67      0.77     87209
           5       0.80      0.89      0.84     12784
           6       0.77      0.89      0.83      5180
           7       0.34      0.86      0.48       487
           8       0.82      0.86      0.84     40601
           9       0.74      0.86      0.80     13949
          10       0.81      0.87      0.84      2795
          11       0.79      0.86      0.82      3234
          12       0.73      0.74      0.74     26054
          13       0.82      0.87      0.84      9709
          14       0.84      0.84      0.84      6041
          15       0.81      0.89      0.85      6658
          16       0.60      0.87      0.71      3901
          17       0.84      0.87      0.86      6408
          18       0.81      0.93      0.87      3969
          19       0.58      0.85      0.69      8442
          20       0.86      0.86      0.86     14571
          21       0.86      0.89      0.87     17589
          22       0.78      0.88      0.83      9448
          23       0.74      0.87      0.80      2815
          24       0.72      0.82      0.77      6549
          25       0.85      0.90      0.88      2814
          26       0.75      0.91      0.83      2710
          27       0.70      0.84      0.76      4226
          28       0.70      0.90      0.79      3119
          29       0.82      0.81      0.81     11991
          30       0.72      0.82      0.77      3100
          31       0.76      0.64      0.70     53973
          32       0.85      0.84      0.85     18007
          33       0.76      0.91      0.83      1218
          34       0.78      0.86      0.82     16884
          35       0.78      0.85      0.81      5632
          36       0.79      0.91      0.84      9448
          37       0.82      0.77      0.79     23332
          38       0.73      0.91      0.81      2021
          39       0.77      0.90      0.83      7402
          40       0.81      0.90      0.85      1694
          41       0.78      0.88      0.83      8749
          42       0.81      0.73      0.76     51226
          43       0.77      0.85      0.81      4534
          44       0.73      0.91      0.81      1933
          45       0.83      0.82      0.83     13626
          46       0.85      0.86      0.85     16526
          47       0.08      0.79      0.14       452
          48       0.57      0.82      0.68      1783
          49       0.85      0.90      0.87     11316
          50       0.77      0.77      0.77      1339

    accuracy                           0.80    590000
   macro avg       0.76      0.85      0.79    590000
weighted avg       0.81      0.80      0.80    590000

469202 590000

Test report:
              precision    recall  f1-score   support

           0       0.95      0.85      0.90      1000
           1       0.98      0.91      0.94      1000
           2       0.90      0.87      0.89      1000
           3       0.95      0.90      0.93      1000
           4       0.53      0.67      0.59      1000
           5       0.77      0.90      0.83      1000
           6       0.94      0.89      0.91      1000
           7       0.97      0.88      0.92      1000
           8       0.65      0.86      0.74      1000
           9       0.82      0.86      0.84      1000
          10       0.97      0.89      0.93      1000
          11       0.93      0.86      0.90      1000
          12       0.65      0.76      0.70      1000
          13       0.92      0.87      0.89      1000
          14       0.92      0.85      0.89      1000
          15       0.86      0.89      0.88      1000
          16       0.89      0.87      0.88      1000
          17       0.93      0.87      0.90      1000
          18       0.93      0.92      0.93      1000
          19       0.72      0.85      0.78      1000
          20       0.84      0.87      0.85      1000
          21       0.86      0.89      0.87      1000
          22       0.85      0.88      0.86      1000
          23       0.94      0.87      0.90      1000
          24       0.90      0.80      0.85      1000
          25       0.96      0.91      0.94      1000
          26       0.96      0.90      0.93      1000
          27       0.94      0.84      0.89      1000
          28       0.91      0.92      0.92      1000
          29       0.92      0.83      0.87      1000
          30       0.94      0.80      0.86      1000
          31       0.49      0.67      0.56      1000
          32       0.86      0.83      0.85      1000
          33       0.95      0.91      0.93      1000
          34       0.80      0.87      0.84      1000
          35       0.90      0.85      0.87      1000
          36       0.89      0.92      0.91      1000
          37       0.75      0.75      0.75      1000
          38       0.96      0.90      0.93      1000
          39       0.91      0.91      0.91      1000
          40       0.96      0.88      0.92      1000
          41       0.87      0.90      0.89      1000
          42       0.52      0.72      0.60      1000
          43       0.90      0.85      0.87      1000
          44       0.95      0.89      0.92      1000
          45       0.85      0.84      0.84      1000
          46       0.84      0.85      0.85      1000
          47       0.81      0.77      0.79      1000
          48       0.94      0.81      0.87      1000
          49       0.91      0.90      0.91      1000
          50       0.97      0.78      0.86      1000

    accuracy                           0.85     51000
   macro avg       0.87      0.85      0.86     51000
weighted avg       0.87      0.85      0.86     51000

43522 51000